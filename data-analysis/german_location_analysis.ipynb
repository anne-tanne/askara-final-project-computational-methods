{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8131a0d1",
   "metadata": {},
   "source": [
    "## Location Analysis German\n",
    "\n",
    "#### Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ea49248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed1e3016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the German language model for SpaCy.\n",
    "nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "351a362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV files\n",
    "df_german = pd.read_csv('../scraping/data/extractor_all_articles_20minuten.csv')\n",
    "df_french = pd.read_csv('../scraping/data/extractor_all_articles_20minutes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb98132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ISO 3166 data for Germany and English\n",
    "german_iso_3166 = pd.read_csv('input/german-iso-3166.csv', names=['ISO2', 'Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6b4a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize text by removing accents and converting to lowercase\n",
    "def normalize_text(text):\n",
    "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('ascii').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "002f6537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply text normalization if the column contains strings\n",
    "def apply_normalize_text_if_str(x):\n",
    "    return normalize_text(x) if isinstance(x, str) else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2798f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_list_of_strings(string_list):\n",
    "    if isinstance(string_list, list):\n",
    "        return [normalize_text(s) for s in string_list if isinstance(s, str)]\n",
    "    return string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d214a599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize selected columns in df_german\n",
    "columns_to_normalize = ['Content', 'Title', 'Header']\n",
    "df_german[columns_to_normalize] = df_german[columns_to_normalize].applymap(apply_normalize_text_if_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "44469920",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_normalize = ['Name']\n",
    "german_iso_3166[columns_to_normalize] = german_iso_3166[columns_to_normalize].applymap(apply_normalize_text_if_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "334318c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data for German countries, cities, and cantons, and normalize relevant columns\n",
    "df_countries_german = pd.read_csv('input/list_country_capital_german.csv')\n",
    "df_countries_german = df_countries_german.rename(columns={\"Staat\": \"CountryName\", \"Hauptstadt\": \"CapitalName\", \"Kontinent\": \"ContinentName\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dc46761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name Variations\n",
    "\n",
    "country_name_variations = [\n",
    "    {\"OfficialName\": \"Vereinigte Staaten von Amerika\", \"OtherNames\": [\"USA\"]},\n",
    "    {\"OfficialName\": \"Vereinigtes Königreich\", \"OtherNames\": [\"Großbritannien\", \"Grossbritannien\", \"England\", \"Schottland\", \"Wales\", \"UK\"]},\n",
    "    {\"OfficialName\": \"Russland\", \"OtherNames\": [\"Russische Föderation\"]},\n",
    "    {\"OfficialName\": \"Südkorea\", \"OtherNames\": [\"Korea, Republik\", \"Republik Korea\"]},\n",
    "    {\"OfficialName\": \"Nordkorea\", \"OtherNames\": [\"Korea, Demokratische Volksrepublik\", \"Demokratische Volksrepublik Korea\"]},\n",
    "    {\"OfficialName\": \"Elfenbeinküste\", \"OtherNames\": [\"Côte d'Ivoire\"]},\n",
    "    {\"OfficialName\": \"Tschechien\", \"OtherNames\": [\"Tschechische Republik\"]},\n",
    "    {\"OfficialName\": \"Bolivien\", \"OtherNames\": [\"Bolivien, Plurinationaler Staat\"]},\n",
    "    {\"OfficialName\": \"Iran\", \"OtherNames\": [\"Islamische Republik Iran\"]},\n",
    "    {\"OfficialName\": \"Vatikanstadt\", \"OtherNames\": [\"Heiliger Stuhl\"]},\n",
    "    {\"OfficialName\": \"Taiwan\", \"OtherNames\": [\"Republik China (Taiwan)\"]},\n",
    "    {\"OfficialName\": \"China\", \"OtherNames\": [\"Volksrepublik China\"]},\n",
    "    {\"OfficialName\": \"Myanmar (Früher auch birma)\", \"OtherNames\": [\"Birma\"]},\n",
    "    {\"OfficialName\": \"Osttimor\", \"OtherNames\": [\"Timor-Leste\"]},\n",
    "    {\"OfficialName\": \"Mazedonien\", \"OtherNames\": [\"Nordmazedonien\"]},\n",
    "    {\"OfficialName\": \"Palästina\", \"OtherNames\": [\"Westjordanland und Gazastreifen\"]},\n",
    "    {\"OfficialName\": \"Niederlande\", \"OtherNames\": [\"Holland\"]},\n",
    "    {\"OfficialName\": \"Republik Kongo\", \"OtherNames\": [\"Kongo-Brazzaville\"]},\n",
    "    {\"OfficialName\": \"Mazedonien\", \"OtherNames\": [\"Nordmazedonien\"]},\n",
    "    {\"OfficialName\": \"Südsudan\", \"OtherNames\": [\"Sudan, Süd-\"]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "910e4c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion of the list into a DataFrame\n",
    "df_country_name_variations = pd.DataFrame(country_name_variations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "c99b5966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countries_german = df_countries_german.merge(df_country_name_variations, left_on='CountryName', right_on='OfficialName', how='left')\n",
    "df_countries_german = df_countries_german.drop(['OfficialName'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "a1769fa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'OtherNames'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'OtherNames'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [275]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m columns_to_normalize \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountryName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCapitalName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContinentName\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m df_countries_german[columns_to_normalize] \u001b[38;5;241m=\u001b[39m df_countries_german[columns_to_normalize]\u001b[38;5;241m.\u001b[39mapplymap(apply_normalize_text_if_str)\n\u001b[0;32m----> 3\u001b[0m df_countries_german[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOtherNames\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_countries_german\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOtherNames\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(normalize_list_of_strings)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'OtherNames'"
     ]
    }
   ],
   "source": [
    "columns_to_normalize = ['CountryName', 'CapitalName', 'ContinentName']\n",
    "df_countries_german[columns_to_normalize] = df_countries_german[columns_to_normalize].applymap(apply_normalize_text_if_str)\n",
    "df_countries_german['OtherNames'] = df_countries_german['OtherNames'].apply(normalize_list_of_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd0990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_normalize = ['CountryName', 'CapitalName', 'ContinentName']\n",
    "df_countries_german[columns_to_normalize] = df_countries_german[columns_to_normalize].applymap(apply_normalize_text_if_str)\n",
    "df_countries_german['OtherNames'] = df_countries_german['OtherNames'].apply(normalize_list_of_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83f62191",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities_german = pd.read_csv('input/list_cities_german.csv')\n",
    "df_cities_german['Name'] = df_cities_german['Name'].apply(lambda x: normalize_text(x) if isinstance(x, str) else x)\n",
    "df_cities_german = df_cities_german.rename(columns={\"Name\": \"CityName\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f50e77d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cantons_german = pd.read_csv('input/list_cantons_german.csv')\n",
    "df_cantons_german = df_cantons_german.rename(columns={\"Abk.\": \"Abbreviation\", \"Kanton\": \"CantonName\"})\n",
    "columns_to_normalize = ['Abbreviation', 'CantonName']\n",
    "df_cantons_german[columns_to_normalize] = df_cantons_german[columns_to_normalize].applymap(apply_normalize_text_if_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0147faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to geocode a location using Positionstack API\n",
    "def geocode_location_positionstack(location_name, api_key):\n",
    "    base_url = \"http://api.positionstack.com/v1/forward\"\n",
    "    params = {'access_key': api_key, 'query': location_name, 'limit': 1}\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data['data']:\n",
    "            latitude = data['data'][0]['latitude']\n",
    "            longitude = data['data'][0]['longitude']\n",
    "            return latitude, longitude\n",
    "        else:\n",
    "            return None, None\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None, None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2cb8fdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add coordinates to a dataframe row based on a specified column name\n",
    "def add_coordinates(row, column_name, api_key):\n",
    "    location_name = row[column_name]\n",
    "    lat, lng = geocode_location_positionstack(location_name, api_key)\n",
    "    return pd.Series({'Coordinates': (lat, lng), 'Latitude': lat, 'Longitude': lng})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881b9d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "geocode_api_key = '1983e85e9a97673a09ed6d19417dda0f'\n",
    "df_cities_german[['Coordinates', 'Latitude', 'Longitude']] = df_cities_german.apply(lambda row: add_coordinates(row, 'CityName', geocode_api_key), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaa37fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_with_none = df_cities_german[df_cities_german['Coordinates'] == (None, None)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010ea839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retry geocoding for cities with None coordinates\n",
    "\n",
    "for idx in indices_with_none:\n",
    "    city_name = df_cities_german.loc[idx, 'CityName']\n",
    "    print(f\"Attempting to geocode: {city_name}\") \n",
    "    try:\n",
    "\n",
    "        time.sleep(1)\n",
    "        \n",
    "        new_coords = geocode_location_positionstack(city_name, geocode_api_key)\n",
    "        print(f\"Coordinates received: {new_coords}\")  \n",
    "        \n",
    "        if new_coords is None or len(new_coords) != 2:\n",
    "            raise ValueError(f\"Invalid coordinates received: {new_coords}\")\n",
    "        \n",
    "        df_cities_german.loc[idx, 'Latitude'] = new_coords[0]\n",
    "        df_cities_german.loc[idx, 'Longitude'] = new_coords[1]\n",
    "\n",
    "        df_cities_german.at[idx, 'Coordinates'] = (new_coords[0], new_coords[1])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error geocoding {city_name}: {e}\")\n",
    "        traceback.print_exc() \n",
    "        df_cities_german.loc[idx, ['Latitude', 'Longitude']] = [None, None]\n",
    "        df_cities_german.at[idx, 'Coordinates'] = (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f889d096",
   "metadata": {},
   "source": [
    "**Add coordinates to capital cities worldwide**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "720cb5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countries_german[['Coordinates', 'Latitude', 'Longitude']] = df_countries_german.apply(lambda row: add_coordinates(row, 'CapitalName', geocode_api_key), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe90a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ISO2 codes for comparison\n",
    "df_countries_german = df_countries_german.merge(german_iso_3166, left_on='Country', right_on='Name', how='left')\n",
    "df_countries_german = df_countries_german.drop(['Name'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43348568",
   "metadata": {},
   "source": [
    "### Search Functions\n",
    "\n",
    "#### Country Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "12a61f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_countries_in_text(content, header, country_data, swiss_cities, swiss_cantons):\n",
    "    mentioned_countries = set()\n",
    "\n",
    "    # Analyze the Content using NLP\n",
    "    doc = nlp(str(content))\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in ['LOC', 'GPE']:\n",
    "            text_lower = ent.text.lower()\n",
    "\n",
    "            # Check if the entity is a Swiss city or canton\n",
    "            if text_lower in swiss_cities['CityName'].str.lower().values or text_lower in swiss_cantons['CantonName'].str.lower().values:\n",
    "                mentioned_countries.add(\"schweiz\")\n",
    "                continue  \n",
    "\n",
    "            # Check if the entity matches the capital name of a country\n",
    "            country_from_capital = country_data[country_data['CapitalName'].str.lower() == text_lower]['CountryName']\n",
    "            if not country_from_capital.empty:\n",
    "                mentioned_countries.add(country_from_capital.iloc[0])\n",
    "                continue \n",
    "\n",
    "            # Check if the entity matches the official name of a country\n",
    "            country = country_data[country_data['CountryName'].str.lower() == text_lower]['CountryName']\n",
    "            if not country.empty:\n",
    "                mentioned_countries.add(country.iloc[0])\n",
    "                continue \n",
    "\n",
    "            # Check if the entity matches any alternative name of a country\n",
    "            for index, row in country_data.iterrows():\n",
    "                other_names = row['OtherNames']\n",
    "                if isinstance(other_names, list) and text_lower in [name.lower() for name in other_names]:\n",
    "                    mentioned_countries.add(row['CountryName'])\n",
    "                    break\n",
    "\n",
    "    # Analyze the Header using simple text matching\n",
    "    header_lower = header.lower()\n",
    "    # Check if the header matches any Swiss city or canton\n",
    "    if header_lower in swiss_cities['CityName'].str.lower().values:\n",
    "        mentioned_countries.add(\"schweiz\")\n",
    "    elif header_lower in swiss_cantons['CantonName'].str.lower().values:\n",
    "        mentioned_countries.add(\"schweiz\")\n",
    "    \n",
    "    # Check if the header matches any capital city\n",
    "    for index, row in country_data.iterrows():\n",
    "        if header_lower == row['CapitalName'].lower():\n",
    "            mentioned_countries.add(row['CountryName'])\n",
    "            continue\n",
    "\n",
    "    # Check if the header matches any official country name\n",
    "    for index, row in country_data.iterrows():\n",
    "        if header_lower == row['CountryName'].lower():\n",
    "            mentioned_countries.add(row['CountryName'])\n",
    "            continue\n",
    "\n",
    "    # Check if the header matches any alternative country names\n",
    "    for index, row in country_data.iterrows():\n",
    "        other_names = row['OtherNames']\n",
    "        if isinstance(other_names, list) and header_lower in [name.lower() for name in other_names]:\n",
    "            mentioned_countries.add(row['CountryName'])\n",
    "\n",
    "    return mentioned_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6be7f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the combined function to the DataFrame\n",
    "df_german['Mentioned_Countries'] = df_german.apply(lambda row: find_countries_in_text(row['Content'], row['Header'], df_countries_german, df_cities_german, df_cantons_german), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ebb1d3",
   "metadata": {},
   "source": [
    "#### Count Country Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "d64d7561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count and sort country mentions\n",
    "country_counts = df_german.explode('Mentioned_Countries')['Mentioned_Countries'].value_counts()\n",
    "df_country_counts = pd.DataFrame({'Country': country_counts.index, 'Count': country_counts.values})\n",
    "df_country_counts.sort_values(by='Count', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "7e7c583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country_count_data = df_country_counts.merge(df_countries_german, left_on='Country', right_on='CountryName', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b62301",
   "metadata": {},
   "source": [
    "#### City Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "aaa2673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find mentioned Swiss cities in text\n",
    "def find_swiss_cities_in_text(content, header, df_cities_german):\n",
    "    combined_text = normalize_text(str(content) + \" \" + str(header)).strip()\n",
    "    mentioned_swiss_cities = set()\n",
    "    for city in df_cities_german['CityName']:\n",
    "        normalized_city = normalize_text(city).strip()\n",
    "        if re.search(r'\\b' + re.escape(normalized_city) + r'\\b', combined_text):\n",
    "            mentioned_swiss_cities.add(city)\n",
    "    return mentioned_swiss_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "c062e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the city search function to the German dataframe\n",
    "df_german['Mentioned_Swiss_Cities'] = df_german.apply(lambda row: find_swiss_cities_in_text(row['Content'], row['Header'], df_cities_german), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f2fcbdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating Mentioned Countries with Switzerland if Swiss Cities are Mentioned\n",
    "switzerland_added = False  # Flag to track if 'Schweiz' is added\n",
    "for idx, row in df_german.iterrows():\n",
    "    if row['Mentioned_Swiss_Cities'] and \"schweiz\" not in row['Mentioned_Countries']:\n",
    "        df_german.at[idx, 'Mentioned_Countries'] = row['Mentioned_Countries'].union({\"schweiz\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "e3ac9250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting and Sorting Mentioned Swiss Cities\n",
    "city_counts = df_german.explode('Mentioned_Swiss_Cities')['Mentioned_Swiss_Cities'].value_counts()\n",
    "df_city_counts = pd.DataFrame({'City': city_counts.index, 'Count': city_counts.values})\n",
    "df_city_counts.sort_values(by='Count', ascending=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "51f6e171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging City Count Data with Swiss Cities Data\n",
    "df_city_count_data = df_city_counts.merge(df_cities_german, left_on='City', right_on='CityName', how='left')\n",
    "df_city_count_data = df_city_count_data[['City', 'Count', 'Coordinates', 'Longitude', 'Latitude']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cbf859",
   "metadata": {},
   "source": [
    " ### Exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "1f00ca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'output/data/df_cities_german_with_coordinates.csv'\n",
    "df_cities_german.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "0ee84a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'output/data/df_german_with_mentions.csv'\n",
    "df_german.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "194c5f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'output/data/df_city_count_data_german.csv'\n",
    "df_city_count_data.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "ecd02fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'output/data/df_country_count_data_german.csv'\n",
    "df_country_count_data.to_csv(csv_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
